form service install:
curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.1/install.sh | bash
exec bash
nvm install node
sudo yum install git
git clone https://github.com/Zalloz/form-service.git
cd form-service
npm i
sudo visudo #change settings: comment out line #Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin
sudo ln -s /usr/local/bin/node /usr/bin/node
sudo ln -s /usr/local/lib/node /usr/lib/node
sudo ln -s /usr/local/bin/npm /usr/bin/npm
sudo ln -s /usr/local/bin/node-waf /usr/bin/node-waf
sudo node server/dist/server.js

nginx:
install 1: sudo amazon-linux-extras install epel
install 2: sudo yum update
install 3: sudo amazon-linux-extras install nginx1
see if its running: sudo fuser -k 80/tcp
stop it: sudo systemctl stop nginx.service
start it: sudo systemctl start nginx.service
edit config: sudo vim /etc/nginx/nginx.conf

sudo vim /etc/sysctl.conf
Append / modify the following line:
fs.file-max = 65535
Save and close the file. Edit /etc/security/limits.conf, enter:
sudo vim /etc/security/limits.conf

Set soft and hard limit for all users or nginx user as follows:

ec2-user           soft    nofile  65535
ec2-user           hard    nofile  65535

nginx       soft    nofile  10000
nginx       hard    nofile  30000

sysctl -p


for others:
sudo yum install epel-release
sudo yum update
sudo yum install nginx
sudo nginx -v

redis:

sudo yum update

cd ~
curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.1/install.sh | bash
exec bash
nvm install node
sudo yum install git
exec bash
git clone https://github.com/Zalloz/form-service.git

cd ~
sudo yum -y install gcc make # install GCC compiler
cd /usr/local/src
sudo wget http://download.redis.io/redis-stable.tar.gz
sudo tar xvzf redis-stable.tar.gz
sudo rm -f redis-stable.tar.gz
cd redis-stable
sudo make distclean
sudo make
sudo yum install -y tcl
sudo make test
sudo cp src/redis-server /usr/local/bin/
sudo cp src/redis-cli /usr/local/bin/
cd /usr/local/src/redis-stable
sudo cp ~/form-service/redis.conf /etc/redis.conf
sudo vim /etc/redis.conf
sudo /usr/local/bin/redis-server /etc/redis.conf --daemonize yes


sudo su
sudo echo never > /sys/kernel/mm/transparent_hugepage/enabled
sudo sysctl vm.overcommit_memory=1
sysctl -w net.core.somaxconn=1024
sudo sysctl -w fs.file-max=100032
sysctl -p

1106000 successes
1393854 unset keys.

my redis doesnt store all the data, going to shard it into 3

1. Created a github organization CHECK!
2. Set up directories CHECK!
3. Set up git workflow CHECK!
4. Set up AirBnB style guide and eslint + prettier UNCHECK!
5. Connect and set up a new CircleCI build CHECK!
6. Clone repo's CHECK!
7. Set up dependencies CHECK!
8. Create tickets CHECK!
9. Set up faker CHECK!
10. Choose 2 dbs
11. Choose 2 ORMs

AWS:
https://www.linode.com/docs/databases/postgresql/how-to-install-postgresql-relational-databases-on-centos-7/
https://www.hostinger.com/tutorials/how-to-install-postgresql-on-centos-7/
https://medium.com/@nishankjaintdk/setting-up-a-node-js-app-on-a-linux-ami-on-an-aws-ec2-instance-with-nginx-59cbc1bcc68c
https://enterprise.arcgis.com/en/server/10.3/cloud/amazon/change-default-database-passwords-on-linux.htm
https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/setting-up-node-on-ec2-instance.html
https://stackoverflow.com/questions/18664074/getting-error-peer-authentication-failed-for-user-postgres-when-trying-to-ge
https://www.linode.com/docs/tools-reference/tools/modify-file-permissions-with-chmod/
https://stackoverflow.com/questions/19463074/postgres-error-could-not-open-file-for-reading-permission-denied

================================

We chose postgreSQL for our SQL database because it has the best performance under high loads.

We chose CouchDB for our NoSQL database because of its ease use and the protocol is http based.
It is document based and has good performance.

================================

Export postgreSQL pg_dump -U username dbname -N topology -T spatial_ref_sys > dbexport.pgsql
Import postgreSQL psql -U username dbname < dbexport.pgsql

Import couchDB cat myFile.json | lwp-request -m POST -sS "http://localhost/dbname/_bulk_docs" -c "application/json"
or cat myFile.json | POST -sS "http://myDB.couchone.com/testDB" -c "application/json"

CouchDB wasnt even close to being able to handle as many requests as psql.
CouchDB had many more errors.
CouchDB was able to respond fast but to few fewer requests than postgres
PSQL's response time is very good.
PSQL is able to handle a much higher load.
PSQL had no errors while CouchDB was having many errors.

I decided to make a bare node server without express off the bat because
i thought id end up doing it anyways and decided to not waste extra work.

With the first loader.io test i got around 100 per second at 1800ms avg res time

Then i refactored my proxy to use a promise.all and the avg res time when down to
1500ms

my max was 120 RPS at 2023ms

michel refactored, changed to bare node and we got almost no improvement.

still 120 RPS at around 2000ms

mike then refactored to promise.all and we saw a very slight improvement

still 120 RPS at around 2000ms

mike then refactored to only use 4 db queries each time and we got about 10 more RPS more.

improvment to 130 RPS at around 2000ms

we both made our production builds and there was no improvement

130 RPS at around 2000ms

now we are trying new relic

tried to reduce our sql max varchar count for each variable which didnt improve any performace

going to try to find out what our bottleneck is think its the db

first we will try using redis
we got redis working got 2350 ms on first run
then after several runs of loader got to 1900ms
then fixed some code error and made optomization then got 1757 ms on 125 clients 

fixed the warnings on redis about over commit memory, huge page setting and some others

set some configs on redis

but over all these havent seem to have changed anything because our redis cache isnt fully populated

we changed the code a bit so our node servers send a response right after a postgres query
if the cache key in redis wasnt found instead of waiting for redis to reply for its set query
to send back a server response

changed the redis no-appendfsync-on-rewrite to yes and got a small improvment, but noticable

making a few postgres server have to do this:
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/form-service/
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/form-service/server/
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/form-service/server/da
chmod: cannot access ‘/home/ec2-user/form-service/server/da’: No such file or directory
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/form-service/server/database/
[ec2-user@ip-172-31-37-128 database]$ chmod a+rX /home/ec2-user/form-service/server/database/schema.sql 
[ec2-user@ip-172-31-37-128 database]$ sudo -u postgres psql -f schema.sql

to import data

had to change the pg_hba.conf

had to change the sudo vim /var/lib/pgsql/data/postgresql.conf

on line 32 to listen_addresses = '*' 

changed shared buffers in sudo vim /var/lib/pgsql/data/postgresql.conf from 32MB to 128MB, huge boost

made them higher 512 shared 384 for temp and got another boost

found out lodader.io behaves weird when you put in less than 250 cps
the amount of cps under 250 varies alot and if you put in 250 it goes to 500 cps

so we are under 2secs at 250 rps

counldnt find much gain from changing more config in either redis or postgres
decided that using redis shards to cache my all the data i would use would be better.

made 3 redis shards and got another 50 rps out of it.

so decided to scale more, made 10 total redis shards and got up to around 400 rps

then looked at my service cpu usage and it was maxed out 

so made nginx load balance 3 services that all talk to the 10 shards and got to 1000 rps immediately

i got a lot of errors but fixed them by increasing ulimits and settings in nginx conf 

1000 rps 1800ms

still my services are using a lot of cpu, will open 3 more

really good results, got 19 ms on 1000 rps no errors

1500 rps at 100 ms
2000 rps at 2k ms 5.1% error rate

servers do well at high loads until they get to about 60,000 total responses, then errors occur.